import numpy as np
import re
import string
import math
from collections import OrderedDict
from functools import lru_cache
from transformers import AutoTokenizer, AutoModel
from tqdm.auto import tqdm
import torch
from typing import List, Dict, Any

# model, tokeniser = AutoModel.from_pretrained(
#     "cambridgeltl/SapBERT-from-PubMedBERT-fulltext"
# ), AutoTokenizer.from_pretrained(
#     "cambridgeltl/SapBERT-from-PubMedBERT-fulltext"
# )
# model.to('cuda' if torch.cuda.is_available() else 'cpu')

ANSRE = re.compile(r'<answer>(.*?)</answer>', re.IGNORECASE | re.DOTALL)

def normaliseText(text: str) -> str:
    text = text.lower()
    return "".join(character for character in text if character not in string.punctuation)

def extractAnswer(text: str) -> str:
    match = ANSRE.search(text)
    if match:
        return match.group(1).strip()
    return text.strip() #Fallback to returning the whole text.

#We want to cache the model and tokeniser to avoid reloading them every time.
@lru_cache(maxsize=1)
def getModel():
    """
    Load and return the medical embedding model and tokenizer. Cache the result to avoid reloading.
    Returns:
        model: The medical embedding model.
        tokeniser: The tokenizer for the model.
    """
    model, tokeniser = AutoModel.from_pretrained(
        "cambridgeltl/SapBERT-from-PubMedBERT-fulltext"
    ), AutoTokenizer.from_pretrained(
        "cambridgeltl/SapBERT-from-PubMedBERT-fulltext"
    )
    model.to('cuda' if torch.cuda.is_available() else 'cpu')
    return model, tokeniser

class TinyLRU:
    """
    A tiny LRU cache to store recent computations.
    """
    def __init__(self, capacity: int = 50000):
        self.capacity = capacity
        self.data = OrderedDict()
    def get(self, key):
        value = self.data.get(key, None)
        if value is None:
            return None
        self.data.move_to_end(key)
        return value
    def put(self, key, value):
        self.data[key] = value
        self.data.move_to_end(key)
        if len(self.data) > self.capacity:
            self.data.popitem(last=False)

cache = TinyLRU()

def reward_rubric(simScore: float) -> float:
    """
    A simple rubric to convert similarity scores to rewards between -3 and 3.
    """
    if simScore > 0.9:
        return 3.0
    elif simScore > 0.75:
        return 2.0
    elif simScore > 0.5:
        return 1.0
    elif simScore > 0.25:
        return 0.0
    elif simScore > 0.1:
        return -1.0
    elif simScore > 0.0:
        return -2.0
    else:
        return -3.0

# def medical_rewards(
#         completions: List[Dict[str, Any]],
#         solution: List[str],
#         **kwargs
# ) -> List[float]:
#     """
#     Reward function that checks if the completion is medically accurate.
#     This is a placeholder function and should be replaced with a proper medical accuracy checker.
#     Args:
#         completions: The completions generated by the model.
#         solution: The ground truth solution.
#         **kwargs: Other key word arguments.
#     Returns:
#         Reward vector (List[float])
#     """
#     contents = [comp[0]['content'] for comp in completions]
#     rewards = []

#     for content, sol in tqdm(zip(contents, solution), total=len(solution)):
#         try:
#             # Tokenize and encode the content and solution
#             inputsContent = tokeniser.encode_plus(
#                 content,
#                 return_tensors="pt",
#                 truncation=True,
#                 padding="max_length",
#                 max_length=512
#             ).to(model.device)
#             inputsSolution = tokeniser.encode_plus(
#                 sol,
#                 return_tensors="pt",
#                 truncation=True,
#                 padding="max_length",
#                 max_length=512
#             ).to(model.device)
#             with torch.no_grad():
#                 embeddingsContent = model(**inputsContent).last_hidden_state.mean(dim=1)
#                 embeddingsSolution = model(**inputsSolution).last_hidden_state.mean(dim=1)
#             #Compute the cosine similarity
#             cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)
#             similarity = cos(embeddingsContent, embeddingsSolution).item()
#             rewards.append(reward_rubric(similarity))
#         except Exception as e:
#             print(f'Error computing medical reward: {e}')
#             rewards.append(0.0)
#     return rewards

def embedText(texts: List[str], max_length: int = 512) -> np.ndarray:
    """
    Embed a list of texts using the medical embedding model.
    Args:
        texts: List of texts to embed.
        max_length: Maximum length for tokenization.
    Returns:
        Numpy array normalised on CPU.
    """
    model, tokeniser = getModel()
    keys = [normaliseText(text) for text in texts]
    values = [cache.get(key) for key in keys]
    toIndex = [i for i, v in enumerate(values) if v is None]
    if toIndex:
        batch = [keys[i] for i in toIndex]
        with torch.inference_mode():
            inputs = tokeniser.batch_encode_plus(
                batch,
                return_tensors="pt",
                truncation=True,
                padding="max_length",
                max_length=max_length
            ).to(model.device)
            embeddings = model(**inputs).last_hidden_state.mean(dim=1)
            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
            embeddings = embeddings.cpu().to(torch.float32).numpy()
        for i, vec in zip(toIndex, embeddings):
            values[i] = vec
            cache.put(keys[i], vec)
    return np.stack(values)

def medical_rewards(
        completions: List[Dict[str, Any]],
        solution: List[str],
        **kwargs
) -> List[float]:
    """
    Reward function that checks if the completion is medically accurate using embeddings.
    Args:
        completions: The completions generated by the model.
        solution: The ground truth solution.
        **kwargs: Other key word arguments.
    Returns:
        Reward vector (List[float])
    """
    contents = [comp[0]['content'] for comp in completions]
    golds = solution
    rewards = []
    preds = [extractAnswer(content) for content in contents]

    #Embed once.
    EmbeddingPred = embedText(preds)
    EmbeddingGold = embedText(golds)
    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)
    similarity = cos(torch.tensor(EmbeddingPred), torch.tensor(EmbeddingGold)).numpy()
    rewards = [reward_rubric(sim) for sim in similarity]
    return rewards

if __name__ == "__main__":
    #Example usage
    completions = [
        [{"content": "The patient has diabetes and hypertension."}],
        [{"content": "The patient is healthy."}],
        [{"content": "The patient appears to have swelling in the pineal region"}]
    ]
    solutions = [
        "The patient has diabetes and high blood pressure.",
        "The patient is in good health.",
        "The patient has a parotid gland tumor."
    ]
    rewards = medical_rewards(completions, solutions)
    print(rewards)